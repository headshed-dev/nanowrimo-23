- {{renderer :wordcount_}}
	- 1st september 2007 I bookmarked the [twiki security plugin](https://twiki.org/cgi-bin/view/Plugins/SecurityPlugin) which is a method of protecting page content in a 'Twiki' or wiki. Its as I remmember a method of 'access control' that you can use in what would otherwise be a public access Wiki. 
	- Web pages back in the beginning, were, as they are now, protected from being changed by virtue of their file systems being marked as read only by users in general and only writable by the owner of the file. This is a file level attribute in the operating system and this pricinple applies for any OS but in Unix this might be expressed as ```chmod 644``` which means that the file is readable by all but only writable by the owner. The numbers 644 refer to the octal representation of the file permissions and relate to 3 sets of permissions, read, write and execute. The first number is the owner, the second is the group and the third is everyone else.
	- A further level of control is provided by the web server itself which can be configured to allow or deny access to files based on the IP address of the client. Additional to this, the http protocol allows for us to 'GET' web pages as it is a 'stateless' protocol. This means that the server does not know who is asking for the page and so it cannot make a decision about whether to allow or deny access to the page. We can also 'POST' pages to the server and this is how we can change the content of a page. The server can be configured to allow or deny access to the POST method based on the IP address of the client. There are more methods, such as PUT, PATCH and DELETE which are used by RESTful APIs to further mutate data on the server.
	- Deciding on who can change data and how this is managed is quite a thing to get right. When we just had something like a Unix server onto which we shelled into, edited pages and saved them, permissions for the world to read our pages under `/var/www/html` were set to 644 and we were done. 
	- But when the idea of 'on line collaboration' came into being, how could be allow people that we approved of to make changes to our glorious web pages?
	- Wiki pages, whilst being usefull as read only web sites were ok but it would have been impracticle for everyone that needed to contribute to pages of data to access a separate system in order to do so. 
	- So we needed something better and we see the result of this in the most well known implementation of a wiki, Wikipedia. It changed evertyhing in the way that information is created and shared. Some of us are old enough to remember something that Microsft called 'Encarta' which was a CD-ROM based encyclopedia. It was a great idea but it was not a wiki and so it was not a collaborative effort. We also paid hard cash for it unless you were able to get an out dated version from a magazine cover disk, which I often did, rather than, as was the custom for many to get a hooky copy from a friend or a market stall. Software piracy was rampant in the 90s and it was not until the advent of the internet that we were able to get software for free and legally through open source software.
- {{renderer :wordcount_}}
	- more on access control through to sessions, cookies and JWT token
	- traditionally, a web page could be protected by configuring the web server to use an '.htaccess' file ( in the case of an Apache or Nginx server ) to allow or deny access to a page based on the IP address of the client. This is a very basic form of access control. 
	- the web server serves to the browser a challenge to authenticate and the browser responds with a username and password. The web server then checks the username and password against a database of users and if the user is found, the web server will allow access to the page.
	- likewise, this same mechanism may be used to 'POST' data to the server and this is how we can change the content of a page. The server can be configured to allow or deny access to the POST method based on the IP address of the client. There are more methods, such as PUT, PATCH and DELETE which are used by RESTful APIs to further mutate data on the server.
	- In the early days of the web, this was a common method to protect access to a 'CGI' script which was a program that ran on the server and generated a web page. The CGI script would be written in a language such as Perl or C and would be executed by the web server. The CGI script would be protected by the web server and would be configured to allow or deny access to the script based on the IP address of the client. It would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- as time went on, it became a more common pattern to use a database to store the data and to use a scripting language such as CGI to generate the web page. This was a more efficient way of generating web pages as the database could be queried and the data could be used to generate the web page. This was a more efficient way of generating web pages as the database could be queried and the data could be used to generate the web page. The web server would be configured to allow or deny access to the CGI script based on the IP address of the client. The CGI script would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- The process of logging in was brought into a web page with form entries to accept the user name and password. The challenge response mechanism was still in place but the user was not aware of this. The web server would be configured to allow or deny access to the CGI script based on the IP address of the client. The CGI script would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- Up to this point, a typical transaction of a user logging in, being authenticated and authorized to make edits to their web pages using a CGI script would be as follows:
		- The user would enter the URL of the web page into the browser and the browser would send a request to the web server.
		- The web server would respond with the web page and the browser would render the page.
		- The user would enter their username and password into the form and submit the form.
		- The browser would send a request to the web server.
		- The web server would respond with the web page and the browser would render the page.
		- The user would make changes to the page and submit the form.
		- The browser would send a request to the web server.
		- The web server would respond with the web page and the browser would render the page.
	- each step of this process caused for the browser to load a complete web page and this was a slow process. The web server would be configured to allow or deny access to the CGI script based on the IP address of the client. The CGI script would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- This pattern became repeated for pages that were not in any way requiring authentication as 'dynmic web pages' were a thing and the web server would be configured to allow or deny access to the CGI script based on the IP address of the client. The CGI script would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- Web pages could be slow to load, not just depending on slow internet connections but also by load on the web server. If this was at a time of peak demand, for example in holiday seasons or at the end of the working day, the web server could become overloaded and the response time for a page could be very slow. Web servers failing to respond to requests was a common problem. 
	- Still today, some websites are using this same pattern of authentication and authorization and it is still a valid pattern but prone to all of the same problems that it always was.
	- Microsoft introduced a feature into their browser that we now know as AJAX. Other browsers adopted this also, mostly to be compatible with the Microsoft browser. This allowed for a web page to be loaded and then for the browser to make requests to the web server for data and to update the page without having to reload the page. This was a great improvement in the user experience and it was a great improvement in the load on the web server.
	- Google adopted this in their maps application which made this new kind of application not only possible but also very popular.
	- The internet changed from being an on line library of information to being an on line application platform.
	- Ironically, this led to Google making available far more applications that were now capable of being used in the browser, something not thought possible before. Google docs, sheets and slides are all examples of this.
	- Microsoft responded with their own version of this and we now have Office 365 which is a suite of applications that are available on line but it was some time before Microsoft were able to make this work as well as Google did.
	- In fact, Microsoft themselves by then had to change their own business model from selling software to selling a service. This was a big change for them and it was not without its problems. This was driven at least in part by Google using AJAX in the way that they did and Microsoft had to play catch up.
	- Not only did Micrsoft change their business models but they also changed they worked with the software development community. They had to change from being a closed source software company to being an open source software company. This was a big change for them and it was not without its problems for them, causing internal frictions and externally, they had to overvome a great deal of mistrust in the open source community in order for them to be taken seriously and be trusted as up to this point, they had been seen as the enemy of open source software, at one time calling it a 'cancer'.
	- Typescript, a means of extending Javascript to have types was a big part of this change and it was a big change for the Javascript community also. It was not without its problems for them, causing internal frictions and externally, they had to overvome a great deal of mistrust in the open source community.
	- As google maps and other apps that followed proved, web pages were no longer just static pages but were now dynamic applications. 
	- A web page could be loaded and individual sections of that page can be updated without having to reload the whole page and this was made possible by AJAX.
	- AJAX stands for Asynchronous Javascript And XML and it is a means of making a request to the web server and receiving a response without having to reload the whole page.
	- In time the XML part was replaced by JSON which is a more efficient means of representing data and far easier to work with in Javascript.
	- Even the process of logging in and authentication would use this same pattern of AJAX requests to the web server and responses from the web server, no longer requiring the whole page to be reloaded.
	- Origonally, sessions were maintained on the server by the CGI scripts through which users accessed web pages. As AJAX and RESTful APIs became more common, the session was moved to the browser and this was done by the web server sending a cookie to the browser. The cookie would contain a session id which would be used by the web server to identify the user. The cookie would be sent with every request to the web server and the web server would use the session id to identify the user.
	- Now, the web server CGI scripts are no longer used and the web server is configured to allow or deny access to the RESTful API based on the IP address of the client. The RESTful API would accept incoming post data and would generate a web page in response, having potentially changed the data on the server.
	- Whilst server based session management is still used, particularly where a high degree of security is required, a newer method of session management is now more common and this is JWT.
	- A JWT token is a means of representing a session in a way that is more efficient than a cookie and it is more secure. It is more secure because it is not possible to change the data in the token without the server knowing about it. It is more efficient because it is not necessary to send the token with every request to the server. The token is sent with the first request and the server responds with a new token which is then used for subsequent requests.
	- The token is sent with every request to the server and the server uses the token to identify the user.
	- A drawback of this is that the token is sent with every request to the server and this can be a security risk. If the token is intercepted, it can be used to impersonate the user. This is a risk that is mitigated by the use of HTTPS which encrypts the data in transit between the browser and the server.
	- A common mistake also is to store the token in local storage in the browser. This is a security risk as the token can be intercepted by a malicious script running in the browser. The token should be stored in a cookie which is sent with every request to the server.
	
