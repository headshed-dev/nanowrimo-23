- {{renderer :wordcount_}}
	- Today I joined a discord group for something called autogen.
	- Autogen is an open source project that is stored on github.
	- I was surprised this morning, watching a Youtube video, that Microsoft is the owner of this repository. Whilst publishded under a creative commons license, it is still a Microsoft project that according to my experience, was not at all common in the past. However, over what has become years of transformational changes, Microsoft have become friendly to open source. There was a horrible level of toxicity in the past, but now, it seems that Microsoft is a different company. The veracity of Microsoft's negative atitude towards Linux, opern source and open standards was so great that even when offered a place to work for Micrsoft a while back I turned down even going to the interview. I wonder occaisonally if I made the right decision but at the least, I dont know how I could have justified this to my partner who had suffered my struggles against Microsoft inspired aggression by others toward me at work in various places. 
	- Right now, I'm not invested in microsoft any more than I use some of their open source products and pay for the use of their office software in the form of 365 on line with all the bells, whistles, bits and bobs that come with it. Teams, dont forget teams, after all, how could we do without teams and who would take us seriously if we couldnt invite people to calls on teams for goodness sake.
	- I have to acknowlege that under their current CEO leadership Satya Nadella who I think is something of a genius to have turned the company around, Microsoft is a different company. I'm not sure if I would work for them, but I would certainly consider it now.
	- When MS bought GitHub, there was a clamour in the open source community to move entire code bases to GitLabs, another rival git repository service on line, so much was the distrust and dislike of Microsoft in the community. 
	- In my view and frakly as I see it now, this was based on mis-conceptions held due to embeded trauma of the past. The only ones really to blame for this reputation would be Microsoft themselves and in particular their previous CEO Steve Ballmer, closely preceded by Bill Gates himself and for the vile things both had said about open source and Linux in particular.
	- As I write this, I am using what is my favoured editor, VSCode, an open source application that is available on Linux, Windows and Mac. I use it on all three platforms and it is is also under Microsoft's stewardship. 
	- I am old enough to remember the days when Microsoft was the enemy of open source and Linux in particular, not to mention the browser wars and the anti-trust case that was brought against them. Even the community of front end developers came out to say how much they disliked Internet Explorer and how much they wanted to see it die. Now it has and we have Edge, which is a Chromium based browser, which is open source and originates from Google, not even Microsoft, yet Microsoft have taken it and made it their own.
	- All of this if you were to speak to me or anyone else who was around at the time, would have been unthinkable. Yet here we are, in a world where Microsoft is a different company and is now a friend of open source, as far as we can tell.
	- Whilst only today I started on the Discord channel for Autogen, AI and tools like Chat-GPT, Bing chat, Bard, Copilot have become tools that I use daily and as a part of my workflow for pretty much a year now and since chat-gpt became widely available. I've learnt to promt these different platforms and have dabbled in creating my own apps using the API's that are available. So the concepts and principles of using chat based Large Language Models is not entirely new to me, this new frontier of AI is something that I have been exploring for a while now.
	- Over time I have witnessed things I and others have called paradym shifts. This I believe is one of them. In technology, I believe that in order to succeed you need to be ready and capable of taking on each of these new 'waves' in technology. Failure to do so is failure to survive and will inevitably lead to ones steady decline and eventual retirement.
	- I dont share the lack of unwillingness to trust Microsoft still held on to by some bloggers and youtuber's though. I can't carry on having bitterness and dislike for what companies have done to me and people like me to now embrace the priciples I've worked with for years to just reject whatever they do, just because they did bad things. I know from watching videos and reading acounts of those that worked in Microsoft since they started to change from 2007 to where they are today that in order for them to achieve this transformational change they had to lose some of the workforce to do it. New people needed to be brought in, amusingly I think to myself, if I had joined them only a few years ago, I would have been part of their new influx of open source thinkers that have helped change microsoft from the ground up.
	- When a big change, like AI comes along or even a new approach to the current way of doing things, be it a new tool, language or framework, I have to decide what to do next and how much of my precious time I can afford to spend learning it. If I were to follow every new shiny thing, in the world of front end web frameworks for example, I can be assured to never finish or delvier a single project and our small company would have no customers.
	- So I get a kind of minor trepidation when new things come along like this. I suffer similar feeling to that as others describe today as 'imposter syndrome', which I call 'self doubt' which is part of something else I know of as 'humility' but where this can go terribly wrong is if you lack the mental hygiene to reign in what should be a safety mechanism that protects you from taking on more than you can chew and turns into a form of mental paralysis that prevents you from doing anything at all.
	- All I can say is, if you suffer from self doubt, you are in good company. If you never doubt yourself and think that nothing is a challenge, you could fall into a category of those that dont think like the majoriy of people. 
	- The older you get and if your still in technology, I defy you, to not realise that you cannot know everything and that there is always something new to learn. Some may say, myself included, the more I know, the less I realise I really know. I will never learn everthing and thus I will always be the student. 
	- The technolgy that calls itself AI and LLMs in particular are taking a lot of attentionand mind share and I guess this is for good reason due perhaps to one thing I see as in common with other things in technology, interaces. Interfaces are a principle of programming paradyms without which, some programming languages could not funcdtion. Systems that we use all have literal interfaces that make it easy to swipe right or left, I suppose that I should know which is which to denote yes or no on dating apps but I've never used one. Point click, drag drop, cut paste, we are familar with these. Without interfaces, we would fail to use the tech that we rely on every day. AI is no different and I think that chat based LLMs are the first to become widlley consumed simply because they use natural language to interact with them, thus unlocking something would have needed a degree in data science to properly understand before this.
	- Over night people are now talking about AI and everyone has something to say about it, how it will change our lives, how jobs will be destroyed, created. Elon Musk says to Rishi Sunack at a conference held at Bletchley Park, home to the code brearkers of the 2nd world war, that one day soon, we wont need to do jobs of work any more, AI will make this happen. 
	- AI has been with us for literally years and before that, we had precursors to it, expert systems, neural networks, machine learning, deep learning. Google have been indexing the internet for all of us to use and calling it 'the search algorithm' but will have been using AI to assess sites authority and relevance to our search terms for years.
	- My next steps down the rabit hole of AI, LLMs and potentially Autogen will be to try and run an LLM on a local system. This I think is fundamental to starting out as without it, LLMs would only be able to be run in the cloud and would have cost implications but also, from the perspective of privacy and control of data and IP would be deal breaker for some. I'm not bothered by this but to cut out an entire market place before I even start would be limiting. 
	- If I can train a model locally, I can train one in the cloud or train locally, saving on compute in the cloud to run the newly trained model in the cloud.
	- With chat gpt, the api is paid for based on the amount of prompts you use.
	- Each prompt is devoid of any knowledge of the previous prompt, so you have to keep track of the conversation yourself.
	- This is like web pages, served to the browser, between each page GET, POST, PUT or DELETE, the server has no knowledge of the previous request, it is stateless.
	- So the pre prompt sent to the api must have enought in it to 'teach' the model what the conversation is about and how we went it to correspnd to us as a response.
	- If we want to pre-poulate the prompt with previous conversation, we need to keep track of this and iteratively add to the prompt.
	- Promts are going to grow in size and complexity as the conversation grows.
	- This works ok for the majority of use cases but I want more. The 'model' that has been trained will have a certain amount of knowledge about the world, but it will be limited to the data that has been used to train it. I've started to notice a sort of personality for each chat AI I've been using.
	- The most mature is by far Chat-GPT, I would almost consider it my preferred personality and like someone I dont mind striking up a conversation with at the coffee machine, whilst bing chat is a bit cocky and abraisive. Bard is a bit simple and copilot is like a child that has been given a dictionary and a thesaurus of code but is severely blinkered in its ability and understanding of the world.
	- If I were to feed the whole of my 2nd brain to chat-gpt, in a single prompt, I might get a response back that sort of sounds like me speaking but each subsequent prompt would have to have this entire 2nd brain in it, which would be a lot of data to send to the api and I'm guessing would ramp up the cost of using it, not to mention introduce significant latency.
	- Training my own model is the only practical way to do this and I'm guessing that this is what autogen or similar tools will hopefully help me to do.
	- Just concatenating the text from your 2nd brain into a single file and feeding it into an LLM is unlikely to have the desired result to just 'become you'. 
	- One approach might be to format blocks of text into questions and answers, so that the model can learn to respond to questions with answers. I would suppose, when doing SEO in web sites, that we've been putting down the kind of question / answer input to trian the Google AI to feed its search database with what our web pages are about.
	- We can't be sure of what is going on in Google and its 'algorithm' as they dont publish this but from me outside, looking in I'm guessing that if I was them, thats what I'd be doing.
	- Another thing I know that can and is being done is using vectors that need to be calculated from an existing data set. This is a low level tool that can be used in databases to create indexes that can be used to find things quickly. I'm guessing that this is what is going on in the background of the LLMs that I've been using. I've so far discounted this as a rapid way to train an LLM as I would see this as a lower level tool likely to be used in the training of the LLM itself or in machine learning but non the less, something we need to be aware of and prepared to re-visit.
	- Another thought I've had is that each block of text in my 2nd brain could have questions created for each by an ai. So the process of re-writing a 2nd brain for ingress into an AI LLM could be assisted with an AI. There would need to be some degree of machine automation as human thoughts tend to come out in a sream ( of councousness ? ) and not naturally in a question and answer format that could be fed into an LLM.
	