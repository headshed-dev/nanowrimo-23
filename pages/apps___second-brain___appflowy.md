- {{renderer :wordcount_}}
	- a while back I was looking at things I could store ideas in, be it a database, notes, whatever
	- the term 2nd brain had not come into my mind or vocabulary and I dont think it was a word bandied about on the interwebs, at least not as much as is has been of recent
	- More accurate a term that represented what I was doing was 'journalling' but with a bit more than just writing a diary of events
	- Everthing that is defined as 2nd brain, the abilty to store, find, retrieve, and use information, is what I was looking for.
	- there seemed 2 main flows for this, text based, in the form of daily journal writing and database based, often using things like notion, or airtable.
	- I spent a bit of time with notion and tried to like it but I wanted more protection of my data, my inner most thougths and ideas. Where are they, if I give them over to a cloud provider like notion, what happens if they go bust, or get hacked, or just decide to change their terms and conditions.
	- Evernote is another like this. I remember warning a customer about using it some years ago, they didnt seem to be bothered by my concerns. Later, much was said in the press and on line about privacy, security of data, personal information in particular. Cambridge Analytica, Facebook, Google, all these companies have been in the news for all the wrong reasons after this and I suppose many were not aware of the implications of using these services, or just didnt care. The 'free lunch' is not free, you pay for it with your data, your privacy, your personal information.
	- I felt a bit of a curmugeon at the time, but I feel that I was right, and I still feel the same way. I dont want to give my data to a company that can do what they want with it, and I dont always want to pay for a service that I can do myself, and I dont want to use a service that is not secure, or is not private when storing things that are personal and private to me.
	- Why should I advocate this for my customers, if this is what I do myself?
	- So giving people the choice is important. If this is still of no concern to people I work with, then that is fine, so long as it does not compromise my own data, or my own privacy and we can work along side each other.
	- But we should all have the option to keep our data prvate, secure and to own it ourselves, and not give it away to a company that can do what they want with it.
	- AppFlowy came up on my feeds just the other day and I took again a look at it as it was wanting to be a notion alternative, but with a different approach, in that it is based on open source, can be self hosted, and is free in this mode. They are now at the point of inviting people to their cloud offering, which will have to be paid for at some point, if they are to make a profitable and sustainable business. Not all things can be free, and I am happy to pay for a service that I use, if it is cost effective for its use. If there is no payment, I have to ask myself, how is this being paid for, and what is the cost to me, and to others, of this service? Is my data being sold, is my privacy being compromised, is my personal information being used for other purposes?
	- I think the project was at the point of just a few people when I looked last, however AppFlowy was being written about by on line journalists this week due to investments being made in the project, and the fact that it is now at the point of being a viable alternative to notion, and other similar services.
	- I had to take a look and watched a youtube video, as you do
		- this one
			- {{video https://www.youtube.com/watch?v=9kyqC8XNQH0&t=512s}}
	- The way I had been journalling, as we can call it, was to just write things down. I've always done this. Early on, when I started working predominantly in tech, I took notes in a small notepad and kept them in a pocket. This allowed me to jot down ideas, bookmark thougths and conepts that were often new to me and refer back. After a while I found I didnt have to look at my notes, my head just started to recall these things and I relied less on written notes. I still write things down but less so now and again, early on working in tech, I decided I needed to learn to type better. Poeple I worked with at night college were touch typists, having learnt this in their jobs. I was fascinated by the increase in productivity that this gave them. One person, like me, was at night school to learn how to program and was coming from a pure office, paper and data entry role. Again, much like myself all those years ago. They were asked often to 'do the typing' if we were doing team work as they could get down the text we needed in reports or whatever, much faster than any of us could, fumbling around in comparison, with 2 finger typing. I have seen journalists 2 finger type which to this day I think must be slowing them down but perhaps they use other techniques to speed up their work flow now. With AI, you can pretty much speak to your phone or tablet and it can have a full human like converation with you, as if you have a personal assistant.
	- Non of that was possible back then, so I knew I needed to get better and so bought a CD in a supermarket where there was a bin of CDs with software, one of which was a typing tutor that ran on Windows. That is how I stared on what is now my second brain.
	- Notes that I made are scattered all over the place, some never to be found again but many, archived on CDs and later DVDs. Over time, I migrated some to cloud, private encrypted services, some of my own. Less sensitive data I used Google Drive and now Office 365
	- If I need more reliable privacy and still storing data in the cloud on Amazon S3 or whatever, I use GPG encryption. I have a key pair, one public, one private. I encrypt the data with my public key and only I can decrypt it with my private key. I can then store this data anywhere, and it is secure. There are tools that integrate with this workflow such as Duply and duplicity that can work together to do scheduled or on demand backups that are encrypted and stored in the cloud. I can then use the same tools to restore the data, decrypt it and use it as I need to.
	- So as needs be, there are ways to store data in a way that is secure, private and accessible, even if you need to use cloud services.
	- As with backups, data privacy and security, there are 'levels' or 'grades' that you can apply to things that you store. Some things are more sensitive than others, and some things are not sensitive at all. You can apply this to your data and store it accordingly.
	- As a person that works very much in text, as opposed to images, video, audio, I have always been able to store my data in a way that is accessible to me, and I can find it, and use it, and I can do this in a way that is secure and private.
	- So these kinds of tools have worked for me and for a long time now, if they have not been called what they are now, a 2nd brain, or a personal knowledge base, or whatever, they have been around for a long time and I have been using them for a long time.
	- AppFlowy, following the path of Notion, is a slightly different angle on note taking and journalling. I avoided Notion however due to privacy and data securty concerns, not knowing if I really 'owned' my data but AppFlowy is another chance to revisit this. Its being open source of course makes it that I could contribute to the project at some point, if I wanted to, and I could also self host it, if I wanted to. I could also use the cloud service, if I wanted to, and pay for it, if I wanted to. So here there are options, rather than deal breakers.
	- The back-end that AppFlowy is written in is Rust. I am not ignorant of Rust but have, for reasons of pragmatism and productivity, chosen to use Go where I have the need as for one, I learnt Go before Rust was really a thing and as a Devops guy, many things that we use in this eco system are already written in Go. But Rust does not put me off. My dabbling with it have not left me feeling cold. The way its build environment works, I like and feels 'right' in a similar way to how I feel using Go. The fact that it has a steeper learning curve, I get but question, who's learning curve ? If your already a polyglot programmer, how steep is steep ? I can understand that learining Rust as a first language could be a bit of a problem and could limit your thinking if your not carefull as it is very opinionated in its approach to things like memory management. If you were to learn this, as a for instance, as 'the way' to do memory mangement, you could, like chickens become fixed upon the first thing they see as their mother, be fooling yourself into this being the only way to do things. I say this because thats what happened to me with my first full on language, Perl. I embraced this as a primary language and exclueded my learnings to it alone, so that I could master the one language. I since switched to many languages and have stopped almost entirely using Perl but I would not have wanted to have been locked in to Rust for as long as I would have with Perl. If that was the way I was learning.
	- The front end is written in Dart. I while back I would have run a mile at the thought. But recently I've been developing mobile apps for Android and IOs and had switched to Dart and Flutter after a short engagement with React Native. I had been using React for a while so this seemed to be a natural progression. However a customer project came up at the start of the React Native one, requireing us to concentrate on an on line, web based social and commuity platform that needed the ability to sell memberships and swag, so this diverted me from the React Native focus. Coming back to it, we re-assessed and looked at Flutter. It seemed that I could achieve a lot more, far more quickly in Dart and Flutter than ever possible with React. Many of the principles of app development in React and other UI frameworks carries across. Even Javascript, a language I still find grossly over using bracketry, nesting and prone to call back hell, has some similarities with Dart and in particular, the Flutter framework. So if you've gone through the pain of learning Javascript, Dart and Flutter is not so bad after all.
	- Dart started out as a language to replace Javascript, requiring for there to be a change to the browser in order to use
- {{renderer :wordcount_}}
	- If the dart project had stayed where it was back in only 2011, so young ! I would likely not have entertained its use, due primarily to the intention of its use to replace Javascript. I really dont like Javascript. As a language, it sucks, it sucks bad. But you have to work with what you've got and trying to replace something when it is embedded in millions of devices is no mean feat. Simply having something that is in place on all those devices and systems is at least something. Getting to this point has not been easy and involved what we 'affectionatley call' the 'browser wars'. So, please, lets not repeat that again !
	- Others have tried to do this very thing, and no bit players in this either. Java, the birth child of Sun Microsystems, rip, now owned by the mighty Oracle, that we are all using its products in some way, even if we dont know it yet, tried to replace Javascript. They wouldnt have thought that they were doing this. Its all how it happened. There was no 'plan'.
	- It makes me laugh. When you go for a job interview you often get asked 'where do you see yourself in your career path in the next 5 years' and you come up with something that you hope makes you sound not like a peasant. But in reality, you have to play the cards you've been dealt. Some have a better hand than you. That's just life I'm afraid and as a person I remember back at University said to us all, "life's hard". And it is. Little is fair but some times you can make a difference and when this happens, I believe that it is our obligation to 'take the bull by both hands' so to speak and [seize the day](https://en.wikipedia.org/wiki/Seize_the_Day').
	- But when you can't practically make a change and it aint totally broke, if we can, lets just get on with it.
	- I was taken by Java and tried to make it work for me but failed. I tried again, three times in my life with various versions and different points in time to adopt it as a primary language. Each time I failed and each time it was due to the myriad of frameworks and libraries of often mind blowing complexity that required diligent work and head space to comprehend, let alone become productive in if you are not doing it for your day job. And as a systems engineer with many many fish to fry, I needed a language or languages that fit in with my circuitous workflows, not one that dictates my daily patterns, with patterns. Ha ha, see what I did there ? Tech joke, sorry.
	- Java applets were the origonal way in which you could 'embed' Java into web pages. This was ace. Very cool and well beyond what you could dream of in HTML and Javascript alone. The problems I think with this were that
		- applets looked ugly. Butt ugly. I dont agree that form or design should ever take precidences over function but lifes just not like that. People like the pretties and if they didnt, we'd all still be working in luminecent green on black terminals like back in the 60s and landing on the moon. Some would be happy with that but they would be the minority, not the majority of human beans.
		- applets needed you to install something in your browser and for some, that simply wasnt going to happen. Often it is said as a kind of off hand thing 'people are lazy' and this is true but also, to quote Mr Michael Cane "not a lot of people know that" - if he indeed did ever say that - in effect, many people dont know how to install software, let alone plugins in their 'browser'. Many users are not even aware of what type of browser they are using, even thinking that they are using 'an app'. Often what people use is that is presented to them as 'the internet', be it 'AOL', 'iTunes', 'Play' or the wizzy world icon that looks like the interweby thing at the bottom of my phone. So you can try to cut it every different way you please but in the end of the day, most users take the path of least resistence and will not go out of their way to improve their experience on the web by installing some other dingly dangly thing
		- applets required a run time that needed to be updated and in the security world, this became somehthing of a nightmare as even if Sun and now Oracle could keep up with all of the vectors of attack that were brought to bare on their code base, more often than not, people still had out of date versions of the run time installed, so even if the operating system was being kept up to date people tend to ignore reminders to do any kind of updates. An example of this is from recently, someone I know of that works in a big organisation had a system that had not been rebooted for over a year and never applied updates despite their desktop becoming completely unusable. Another would be the NHS and wanacry ransome ware. This happened due to a lack of update policy enforcement. The NHS have no money. So they couldnt afford to keep things up to date.
	- Another contender to what has become Javascript, CSS and HTML applications was flash. Adobe, not a small company by anyones stretch of the imagination
		- there were many issues with security, same as with Java Applets
		- flash looked flashy, it did look ok and as such it endured for much longer than Java applets. After all, it if looks good, it must be good.
		- but the thing I think that broke flash was Adobe simply couldnt keep up its upkeep, in light of the amount of platforms they needed to support
		- another thing that broke flash was I believa a fall out with Apple who stopped supporting it in their browser, safari. Again, mosly people wouldnt have even be aware that they were using safari, let alone they could use a differnent one, as aftar all, that's the main thing you press on in your iPhone doody device, so that was soon to die the death, and so it did
	- There were others, silverlight was one I can think of, well, that's another story. Other language based attempts were made in history. I remember one that allowed the use of Perl in the browser, that one makes me chuckle. You could spend a good time researching these lost histories but much of which would be little better than a curiosity and could be a waste of valuable head space
	- In the future though, there is one other contendor and that is WASM ( [Web Assemby](https://webassembly.org/) ), now that, that is a possibility. This is a standard that has been accepted into most modern browsers and devices. It is thus a possible compilation target for something that could very realistically userp or at least become an integral part of Javascript frameworks and applications.
	- However, WASM is still a future technology as although it has a runtime that is accepted and implemented, in order to get something out that could be quickly adopted, some things are missing in the specs. One such is memory management. Garbage colletion is a thing many languages, Java to say the least, rely upon. Rust is one of the few languages that is widely excited over that does not need this. Interestingly, some have completely ignored this and Microsofts blazor framework compiles C# to WASM so if you use this technology to create back end and front end UIs you can completely avoid knowing any Javascript, as your code is compiled into a tiny bit of carrier Javascript buit a whole lot of WASM. Only problem as I see it is the size of the payload that this produces, as in order to compensate for the lack of garbage collection in the run time, this and other language specific dependedencies need to be compiled into the WASM package. This is the same for any language, bar Rust and similar, that can be used to cross compile WASM.
	- I really like the idea of WASM, even of using one language to create both back and front end applications, cross compiling and transpiling all the way. In time, this will be 'the way' I have no doubt but it wont likely be the way we think it will be, if history is anything to go by. No one could have guessed that Javascript would be where it is right now but it is.
	- In my little mind I think that we could see new ways of programming and in effect, new languages or paradigms as a result of and bi-product of AI and large language models. We could see what we understand as 'frameworks' today like Blazor, React, Rails, Angular etc. become something we communicate to an AI that will code it up for us. Newer / better ways of doing tings thus wont need for us to learn a new thing. People moan on line now about the amount of different frameworks that seem to emerge on a weekly basis and this is true. But care to think, what that could be like with AIs both writing and learning new frameworks. We could have new versions, entirely new approaches to developing applicatiions daily. Nightmare !
	- So this is why I didnt want to use Dart to compile code for browsers as at the beginning of Dart, this would have needed for a run time to be installed or a version of Chrome or whatever to run it.
	- The plug was pulled on this though and rather than a compiler, a cross compiler / transpiler approach was adopted by the Dart team. A lot of this I guess would have been down to Google's steer but it would have also been a lot of negative feedback from developer communities that would likely have voiced something similar to my above ramblings.
	- Now, dart is a contender not to replace Javascript but for Javascript to be a compilation target.
	- Lets not miss out the killer app of the stack though and iOS that uses Objective C and or Swift and Android with Java and or Kotlin also became compilation targets for Dart. This is no mean feat. I can only think that this gargantuan effort was achieved by Google backing these efforts.
	- And that is not all. As if having 3 platform targets were not enough, more have been added.
	- Windows desktop and Mac desktop are also targets for Dart.
	- Flutter, the overiding framework written in Dart is the glue that makes all this possible. Its sort of the framework is become the language. At least that is the way many see this as you would find 'flutter' being google'd perhaps more than Dart
- {{renderer :wordcount_}}
	- another thought I had about the state of users / programmers / consumers / producers
		- other day I had a conversation with a person my own age, pretty much same physical origins
		- they said to me that they 'really are not good on this technology thing' and I knew not to say anything more about what we do in our company - as he had asked for, so switched to things I knew he would have seen, as have I, regardless of interests and Star Trek, from the 60s. Most people have to at least know what that is, without at least trying very hard not to. I said that AI is moving so fast, its like faster than warp 10 in star trek. That's how fast its moving
		- so there will always be a community in which you will never be able to talk with about technology as they will default to stand by mode at the mention of technology, even though the majority of these will still use technology in the form of a tv remote to a mobile (dumb) phone or a smart phone or tablet, whilst maintaining a chosen perspective of not being at all technical or rather, not wanting to know any more than is absolutiely necessary.
		- this is a shame as I suspect it could be born of a fear of technology, perhaps simiilar to people thinking that the just cannot do math, cannot read or write, for whatever reason. Perhaps negative experiences in the past have embeded these ideas
		- I wonder if these kind of thoughts will persist as time goes on, or if we will always have some with the tendency to avoid things they would otherwise find intolerable or uncomfortable for whatver reason this may be. Theres a thought.
	-