- {{renderer :wordcount_}}
	- Chat-GPT in barely a year now has become a game changer for data and tech workers like me but has become accessible to programmers and non alike. This is because of its interface being chat based, allowing us to type normal sentences into a text input and have the AI recieve it, interpret our speech and respond with answers that are also in the same natural language.
	- I can understand why this has caused such a rucus amongt our political elites who are repeatedly tardy in their lives and personal study habits as regards the march of technogy such that when a bombshell like this appears, they react a lot of them like clucky chicken says that the sky is falling in.
	- I do agree that this poses an exstostential threat to our lives when an enabling technology like this gets into the hands of axe wielding homicial mainiacs, terrororists and anarchists. That's a given. The same applies to automatic firearms, yet the gun lobbies in the US for instance still seem to have influence over these being banned for members of the general public to purchase them, even when they are unhinged enouth to use them on rampages of killing through public places taking the lives of innocent children and people that have done nothing to offend them.
	- Are AIs going to take over our jobs ? Certainly yes, if those jobs can equally or even partly, done by AIs. This is what is called progress. It is not nice, it is not something that has a concience and those in charge of what is happeing in our lives are not all benevolent, caring, loving individuals with our interests at heart.
	- When the world needed garments to be produced and machines could not do this for us, we had cottage industry where work was democratised for small comunities to flurish and to some small degree prosper where they could become hand crafters of cloth and garments. But when the automated loom was created, this ended in less than a decade and entire swathes of communities and livelihoods were displaced in a way that was not nice. I wonder how many died as a direct or indirect consequence of this so called 'innovation'.
	- Attempts that may or may not have been made by leaders of the day likely did nothing to affect the outcome and with my cynical hat on, I would say much the same of AI. Most politicians and techocrats are likely posturing ritght now by seeking media attention when they speak at summits like the one held at Bletchley in the Uk and elsewhere when they pontificate how we need to regulate AI and protect us from it destroying our lives and livelihoods.
	- Some will be genuine in their thinking that we should, rightly, moderate and regulate AI technology so as for it to be a force for good, rather than a devastating innevitable meltdown.
	- But something tells me the bad actors are using this as an opportunity to white wash what they have been planning to do for years anyway and we all know, nothing is there that can really stop them
	- The biggest problem chat-GPT has right now is that the way it works, as an interface at the transport layer, is pretty dumb. Each 'chat' if you will, is devoid of any previous and as such is 'stateless'. Much in the same way as any web based, TCP traditional HTTP interaction and as such, nothing much has changed this way of working on the internet since it started out back in the before times pre Y2K
	- So for for a conversation to take place between you and the agent, Chat-GPT service enpoint that is, your client software, the browser or app in the case of Chat-GPT, has to itself 'do the job of remembering' for you and what it does is caches the initial question you first ask, post it to Chat-GPT, get the response, take your 2nd / 3rd and so on question and for each, separate posted request for comment to Chat-GPT, build in or 'pin together' each question, answer, question, etc ...
	- This results in a 'paylooad' that is ever increasing and it why, in the case of bing chat for instance, you are limited in the amount of questions you can ask before having to start a new conversation.
	- What in truth happens at the API endpoint is that your 'question' which for each transaction, or rather, further questions become truncations of each, get parsed into that we would call 'words' but what in GPT are now 'tokens'. Some words are just 1 token each but longer words, that it categorizes as 2 or more concepts or meanings can be 2 or more 'tokens'. The amount of tokens a chat can have are limited by each LLM. Chat GPT 3.5 turbo will have less tokens that it can accomodate as opposed to GPT 4, which is more expensive to buy and which will handle significantly more of these 'tokens'.
	- When your chat grows in size, at the moment the agent just bumps off the older tokens and thus loses information related to your chat when you first started out. This is why long running chats tend to lose the point of what you started out with on the free version of Chat GPT but the same is innevitable with newer, more expensive versions of the same.
	- the new phrase 'Mem-GPT' is based on papers and speakers that have tweeted and presented what they like to describe as a sort of 'operating system' for LLMs
	- a mem-GPT agent will have the ability to manage its memory, in a way similar to how an operating system does this with RAM ( random access memory ) when it starts to 'page' or swap in and out memory to disk when it runs out of space to do the same in its more limited random access memory. So nothing new here really but that wont stop this from getting into the Guardian at some point soon no doubt as if this is the next tidal wave of destruction brought to us by the use of AI or similar.
	- This means that we must migrate our LLMs to those that support mem-GPT as the current ones will still do the same 'fifo' ( first in first out ) kind of mindless buffering as previous. What then ensues is the newer agents will still operated in the same 'connectionless' mode of transfer as to which we are currenltly accoustomer do which is still as dumb as before but now with extra wiz bang. Each session will have state persistence so it can 'live again'
	- Programs have been doing this for years and this has been called many things, persistence, state persistence, freeze - thaw, seialisation / de-serialization however the orchstration of this I suppose yes, could require a bit more thinkig and foresight but again, nothing that new but it could be somehting we are convinced into paying more for, who knows
	- its all a step in the right direction though and putting my blue sky glasses on I would say, yes, this could be dawn of a new era of truly network, cloud based operating systems architecture when we now start to conceptualise not physical servers or processors, virtual machines, nor containers or services but now 'agents' as nodes in a network of logical processors that each act as neural networks that can be invoked upon demand and consume as little or as much resources as are required, scaling up or down and creating dynamic experiences and services we are only just starting to imagine what they may be