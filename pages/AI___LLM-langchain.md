- {{renderer :wordcount_}}
	- AI and Large Language Models have been all the rage in the last year. I was initially skeptical to use Chat GPT and other things like it, gitub copilot remained in its secret club mode untill Github generously and bountiously invited me to their beta trial for just short of a whole calendar month prior to their paywalling the service. I am so gratefull to them for being so inclusive and generous. But other LLM based tools did not suffer from such exclusivity and rather, welecomed and continue to welcome free use of this emergent technology. If you want chat GPT version 4, and other premium services such as those related to image generation, you will have to pay for these but this is acceptable when you can access limited functionality for low or no cost in order to learn, test and experiment with the technology. I heard in a recent video from fireship.io that copilot, whilst charging $10 per month, is known to run at loss, with some developers that are heavy users of its service costing them in real terms 8 times or more than this per month. All of this is interesting to see what is likely to happen in the near future in terms of real costs past on to consumers. In the mean time, we exist in a bonanza of free to use tools and services that are to some degree or wholly AI driven.
	- early schepticism is replaced for me now by a desire to know more and use more, rather a wish to ebrace a new way of working and new technolical wave instead of tr
	- There will be money making opportunities, no doubt, in the new and emergent technolgies that comprise of what is currently 'weak AI', the place we are right now in the projected time line of AI development. It is predicted that AI will progress from the hard facts and realisations of AI as we see it now in the form of smart chat bots, voice recognition built into home assistants, search algorythms and interferance with social media feeds by bad actors towards what in theoretical AI is termed as 'general purpose' and 'strong AI' being the penultimate in which AI is able to think for itself and make decisions based on its own reasoning and not just on the basis of the data it is fed. I suppose you could say it would be able to eat its own dog food, pick up its stethescope and walk.
	- For me, the biggest barrier to using AI is the way in which it is used or made accessible. I took a look at a bunch of courses and materials related to the subject area. Googl have some data science courses that are on line and free and will take some of my time. Untill, I would gestimate, a year or so ago it would have been safe to say that if you are a data scientist you will be conversant with the field of data science with a good proportion of this being statistical and pure mathmatics.
	- I can do math, both pure and statistical maths and this comprised a proportion of my degree back in the mid 90s had this stuff in it and I fully expected to use it in programming and technology. I was wrong. As most people in any industry are these days, most are not conversant with maths beyond basic arithmetic and tend to avoid algebraic formulae. So I'm left in a place having less developed mental muscles in this area. This proved a barrier to entering the field of data science.
	- However, time and progress has changed things and I am sure that I am not alone hitting speed bumps being able to adopt AI technology.
	- Chat bots I would say were the biggest change in this world, making AI accesible to anyone, be they matmatical geniuses or not. Indeed, many peope that perhaps should not have access to this technology are now free to do so.
	- Programatic accsess is also now available to non data scientists in the form of API's and SDK's, which to me, are more game chaning than chat bots, as this opens up the possibility of building new solutions using AI and LLMS.
	- There are still limitations on the nature of the interface with AIs from the users perspective, be it chat bot based or API driven. Each request that goes to the LLM is a single request and the response is a single response. This is not a conversation and in order to establish a conversation, each subsequent request must be based on the previous response. So a managed state needs to be maintained as the LLM is stateless and cannot learn from its mistakes or from user feedback. It cannot remember you from one request to the next.
	- In the short term this is solved with software and if you are to use tools to do this, you will need to be able to program or will need to use on line services that do this for you.
	- Langchain is an open source library that is designed to address some of these problems.
		- https://www.freecodecamp.org/news/langchain-how-to-create-custom-knowledge-chatbots/
		- https://github.com/langchain-ai/langchain/blob/master/LICENSE
		- https://www.langchain.com/
		- https://python.langchain.com/docs/get_started/installation
	- Langchain is licensed under the MIT license so is free for us to use and modify if we are able to and to use in commercial projects.
	- It is written in Python and is available via pip so as long as you are familiar with Python and can use soemthing like virtualenv, anaconda, pipenv, poetry or your chosen tool for managing python environments, you should be able to get this up and running relatively easily. I see that a lot of data scientist dont want to learn infrastructue tooling and software development tools like IDEs, source control, pipelines and so on and opt to use Jupiter notebooks. But if your like me, dont be put off by this as they are just python code that are annotated with markdown and can be run in a terminal or in an IDE. I wrongly supposed that some projects were in some way written in a different language to python and that I would have to learn a new language to use them. But this is plain and simple not the case and I believe that there are plugins in VS Code that can extract the code from the notebook and put it into a python file for you if you dont want to do this yourself, but splitting out code from markdown is not a difficult task.
	- Another libray, this one by Microsoft but also open source is [autogen](https://github.com/microsoft/autogen) it is published under a [creative commons license](https://github.com/microsoft/autogen/blob/main/LICENSE) but non the less may be used in commercial projects but likely with the need for some form of attribution.
	- What these and other tools like them have in common is that the basic principle of sending a 'prompt' to the LLM and getting a response back is the same. What the tools often do is to manage the state of the conversation for you and to provide a way of managing the prompts and responses.
	- Langchain offers a greater degree of flexibility in the building of different kind of applications as I would guess looking at it that its tools are lower level and more specific to how information is processed before, after and during the conversation with the LLM. Also, workflows could be built with Langchain that are not conversational in nature, rather, they are more a series of operations that process promts, responses and other data, acting in a similar way to a pipeline or chain of events. I guess this is where they get the name from.
	- Autogen however I feel is a slightly higher level approach to the same set of problems and what it makes possible is the orchestration of multiple 'converations' each as an 'agent' that can be organised in a way that each can talk together in a sort of 'team' approach. This way, you can build a 'virtual workforce' comprising of for exampl, a team of programmers, testers, project managers and the human side can be interfaced with an agent that acts as a proxy that talks to the virtual agents in the same way that a human would talk to a team of people.
	- So there are a number of big things going on here, not just the AI and LLM tech.
	- If it were not for a lot of this being open source, such as in the case just recently of chat GPT and my inabililty to access copilot whilst Github held it private to then stick it behind a paywall, we would not be able to even have this conversation.
	- The rise in importance of open source and open team work and collaboration that has been subsequent to this has only really started to have an impact in the early 2000s but started before that, most famously with the Linux kernel and the GNU project.
	- I saw this seen as a thing people saw as 'nerdy', or 'geeky' but also picked up on some peoples anger and fear of this also leading in some to be come 'linux haters' as I would now call them. Why else would Microsoft have to say that they 'love linux' in order to try and dispell this association.
	- I heard an interview with someone on a programme called 'the life scientific' earlier between Jim Alkaleely
		- >“Big data” and “data science” are terms we hear more and more these days. The idea that we can use these vast amounts of information to understand and analyse phenomena, and find solutions to problems, is gaining prominence, both in business and academia.
		- >Cathie Sudlow, Professor of Neurology and Clinical Epidemiology at the University of Edinburgh, has been at the forefront of enabling health-related research using ever-increasing datasets. She tells presenter Jim Al-Khalili why this type of research matters, how the COVID-19 pandemic changed attitudes towards data in healthcare, and why the NHS gives the UK a big advantage when it comes to population-wide studies.
		- > Over the course of her career, Cathie has held a variety of roles at different organisations, and she is currently Chief Scientist and Deputy Director at Health Data Research UK. She believes that there is no room for prima donnas in science, and wants her field to be open and collaborative, to have the most impact on patients’ lives.
	- At the opening statements in here interview, I was interested to here Professor Sudlow say that she believed that we need to work more collaboratively and that there is no room for 'prima donnas' in science. She went  on to say that some have become more pre-ocupied with the placing of their names in papers and the acolades given for individual work rather than the work itself being the measurable output. That output is innevitably the product of teams of people working together and this is what she seeks to promote and encourage.
	- If we put everything behind a paywall or under the terms of copywrite, we would not be able to have the opportunites that we have now in the field of AI and LLMs.