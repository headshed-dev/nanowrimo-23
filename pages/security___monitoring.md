- {{renderer :wordcount_}}
	- Monitoring is something I could put into a category of its own but I put it under a heading of security because it is a security concern. Indeed as time has gone on, I have found it has been entirely ignored by some as we have adopted cloud based solutions and some have assumed that it is someone else's problem.
	- Monitoring is a key part of any service. It is the way we know that things are working as they should be. It is also the way we know that things are failing.
	- Both are as important. If you are in the unfortunate situation of serving customers with whom there is a bad relaitionship, that is, for whatever reason, trust is lost and whatever goes wrong, you, the supplier are seen as the first place to point the finger, then monitoring is your friend. It is the way you can prove that you are not at fault. Trying to regain trust is very difficult when it has been lost. But if you are to stand a chance of doing this, good monitoring is essential. What this does is to give you statistics that you can use to show that service has been maintained and can be used to diagnose problems, even if they are not your fault.
	- If you dont have this in place, the customer will be assured of being the ones to tell you that there is a problem. This is not a good place to be.
	- If you do have good monitoring in place, you can be the one to tell the customer that there is a problem. This is the better place to be and it will reduce the stress on your team and downtime for your customer as you will be alerted to issues before they escalate.
	- Monitoring is not just about the service itself. It is also about the infrastructure that supports the service. If you are using cloud based services, you will be relying on the cloud provider to provide the infrastructure. But you will still need to monitor the service. If you are using your own infrastructure, you will need to monitor that too.
	- A common mistake I have seen in the modern age of cloud and agile is for services and software to follow best principles in all aspects of software creation, iteration and deployment but to ignore monitoring. The overwelming mindset is from a development point of view and an over enphasis on testing being something that is done by the development team but somehow no longer needed when the software is deployed.
	- I think that this is a symptom of another trend that I have seen in the last 10 years or so. That is, the move away from the idea of a system administrator. This is a role that has been replaced by the DevOps engineer. This is a role that is more focused on the development side of things and less on the operations side. This is a role that is more focused on the software and less on the infrastructure. This is a role that is more focused on the development team and less on the customer.
	- Flippantly I call this 'DevDev' as it is a role that is more focused on the development team and less on the customer and an idea that we no longer need operational thinking.
	- it is not surprising as automation has meant that increasingly, outdated and expensive processes once done by operational staff are now done by software. This is a good thing. But it does not mean that we no longer need operational thinking. Operations popele that did not adapt to this change have been left behind. But the need for operational thinking has not gone away. It has just changed.
- {{renderer :wordcount_}}
	- Having spent a lot of my working life having used service monitoring and at the lack of solutions pre Y2k, developed bespoke solutions that integrated monitoring into many customer solutions and services, this all done by a team of specialist engineers at one of the leading IT service providers at that time, I think I am able to be a reliable witness as to its history and general adoption
	- I remember how I got involved in this was by being approached by a guy called John Connor, who worked in the supprt team for Internet Managed Services at that time. He was interested to take what he had developed with the name Webcheck to a new level. We would call this Webcheck 2.
	- A bit like Deep Thought in Hitchikers Guide to the Galaxy. The first one was pretty good but the second one was going to be bigger, better and have far more features.
	- That was the plan at any rate but the core principles of the solution never really changed. The number 1 feature was that the monitoring engine, which we called it, would do a job of checking a list of servers and services and tell us if any went out of wack.
	- This sounds simple but the things that are being monitored are hundreds of different systems and services in a farm of web services that a multitude of customers are relying on. Ther is no one size fits all that we can just point a tool at and say, 'monitor that'.
	- John, like other big minded thinkers before and since, came up with a set of principles for solving the problem and reduced each into a process and solutions that could be used by everyone in the team and based on open source software.
	- I guess the key strength of Webcheck, aside of a centralised database of all service status that could be relied upon to tell us within minutes if there was a problem, was that it had many what we called agents that could be deployed to any server and would report back to the central database but were all based on the same build and configuration that were only different in that some were for say, Solaris, some for Linux, some for Windows and so on. Each agent ran a set of standard and custom checks that were each plugins that could be written in any languages, so long as they could each be run as a command line and return a status code.
	- It was this guiding principle sthat made this solution a success I think as it meant that any devloper, operations person, whoever, that can at least write a simple script that can do some checks, print out a result and return an exit code can write a plugin that can be run by the agent and report back to the central database.
	- We today ofcourse have more monitoring solutions that we can shake a stick at but at the turn of Y2k, there were few and most were proprietary and expensive. Nagios did not exist at that time, only its predecessor, Netsaint. We used this but had already adopted Webcheck as it was there when it was needed and it worked.
	- Most software we have has been created out of need, not want and suits a specific use case, for which there was at some point not anything else there to do the job. This is how Webcheck came about. It was a solution to a problem that was not being solved by anything else at that time.
	- I got a mail From John a few years back, saying the last of the WebCheck servers had been decomissioned. It was in 2017 TODO - check date. I had left the company by 2007 so it had been running for a long time, considering its 'engine' was written by me in 2000. There were lots of moving parts in this solution and I wastnt alone in developing it. There were many people involved in its development and maintenance over the years. I was just the one that wrote the core engine and that likely got re-written by someone else at some point. I dont know. I was just glad to hear it was used for so long.
	- It has been interesting to see what we did back then and what has been done since in terms of what is monitored and what is considered a check of availability, performance and so on.
		- We had a set of basics, sort of bread an butter checks that you would do on a server.
			- Is it pingable
			- Is it responding to a web request
			- Is it responding to a database request
			- Is it responding to a mail request
			- Is it responding to a DNS request
			- Are there a list of sockets open that we are expecting
		- Other monitoring solutions I have come across since then, pretty much ended at this point and that was considered adequate for monitoring a server.
		- Often though you could end up with a service reporting back that it is 'up' when in actual fact, multiple services behind this simple check are non funcdtional. The experience for the customer is of their service being denied.
		- Next to happen is that the customers give up and go do something else, perhaps never to return or on occasion, they call up with a problem. 'My website is down'.
		- Interestingly we got quite a lot of the latter in those early days of the Internet and not all of them were nice about it.
		- One time I remember a colleague of mine taking a call from a customer that was pretty high up, a company director of the retail group I believe we were working with stating that their site was down. As we had Webcheck, my colleague was able to check if this was indeed the case for him to find that not only was the site fully funcdtional but it had been for a very long time.
		- This is another core principle of monitoring. Its not just enough to say that somehting is available right now, you need to be able to say that it has been available over time. This is what we call uptime and to have literally hundreds and thousands of service checks, each with a green light by them, each with a history of uptime, is a very powerful thing to have.
		- It turned out that the customer was not able to access the web site though and my colleague asked them to see if they could access other parts of the site, not just the front pages, then could they access another website that was completely different to the one they were trying to access. At this point it was realised that the customer could not access the internet at all and a reboot of his modem was required to get back on line.
		- This is another principle of monitoring and service provision. If you dont have evidence of your service being available, a shower of complaints from customers will be the first you know of a problem and you will take the blame for things that you are not responsible for.
		- I've experience of this first hand in several organsiations that I've worked for where monitoring has been neglected and a customer may even claim that problems they have internally are down to your service. Installing better monitoring can bring back the relationship into something more affable but you really dont want to go there in the first place. The best time to start monitoring is before you have a problem and that is from the start of the service being provided, not when things have gone wrong and reputations have been damaged.
		- We are not just happy to do the basic checks then, things we called back then 'external checks', that is checks on systems from their outside and that can all be done from a separate server, next level down we do system checks and there are basics for these that we can do on pretty much any system
			- Is the disk full
			- Is the CPU busy
			- Is the memory full
			- Is the network busy
			- Is the swap space full
			- Is the system load high
		- these can all be pretty simple checks to do, you'd think so wouldnt you ? But on large systems with many CPUs and threads to boot, where there are many filesytstems and mount points and of varying size. You can't just say '80%' full, send an alert when that filesystem is running to a petabyte as 10% of a petabyte can still be quite a way to go. But that's not good to just say, alert me when I'm 99% full, as even 1% can be quite a bit to go too. So we switch from percentage to megabytes and gigabytes and terabytes and so on. Problem solved, or is it ? What if we have a filesystem that spends much of its time nearly full but never grows, why get someone out of bed at night to find that a disk has grown by 1 megabyte in a month but breached alterting. So we need to analyise the trend of the filesystem and alert when it is growing at a rate that is not normal. At the very least we need a visual way to see this in the form of graphs and charts but ideally, a growth rate needs to be calculated and an alert sent when this is breached. For this to happen you need a database to store the figures that are captured by your monitoring systems and a way to query this database to get the information you need. This is where the next level of monitoring comes in, the database level.
		- Beyond the basics we can have a system that passes on all of these but has an application that is not working. This is where we need to go beyond the basics and start to monitor actual services that the application requires
			- Is the database responding
			- Is the web server responding
			- Is the mail server responding
			- Is the DNS server responding
			- Is the application responding
		- Depending on how good your checks are, you can still fail to pick up critical service failures unless you actually interact in some way with these services
			- can I insert a record into the database
			- can I get a record from the database
			- can I send a mail
			- can I receive a mail that I previously sent
			- can I send a web request and get a web page back and does it contdain the expected content
		- There is another core concept of managing availabity which some called 'experience check' and others call this 'end to end check' or 'customer experience check'. This is where you actually interact with the service as a customer using code to do it.
		- At the beginning of the Internet and e-Commerce web sites we had no tools that had fancy GUIs to do this so in the same way that the search engines ran 'spiders' to crawl the web, we created our own 'web clients' that did similar but not to index the internet, rather to test the availability of our own services by interacting with web sites, checking page content, follwing links, filling in forms, adding items to shopping carts and so on.
		- I have found this to be very powerful as it starts to become a test framwork that extends from the developement life cycle, so if you can develop your applications with this in mind, you can simply carry on running a subset of your integration tests as part of your monitoring solution. This is a very powerful thing to have.
		- Sadly, this is often not done and situations I have seen are where it has not only been overlooked but also made almost impossible to do, where customer service websites may only recieve requests from valid customers, with bank accounts and billing history together with a host of highly confidentail data. Runing a test in this kind of environment would require in some cases for a fake bank account to be set up, with a fake billing history and fake customer data. This is not something that is practical, even legal to do.
		- The only way really to achieve this kind of quality of service monitoring is to build it in from the start and to have a test framework that can be used for both testing and monitoring. - All too often I've been met with blank stares when trying to set up even the simplest form of interactive monitoring, on large systems and small, where testers even have asked me 'why to you need this ?'. At least we need to say 'why to _we_ need this ?' as it is not just the devops guy that needs this, it is everyone that is responsible for the service.
		- active / passive - polling intervals, passive / polling
		- transports https, smtp, icmp
		- submarine
		- healthcheck